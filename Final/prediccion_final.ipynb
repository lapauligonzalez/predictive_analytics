{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importo librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpieza de datos para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/paula/OneDrive/Documentos/Facultad/Análisis Predictivo/final_predictivo/dataset.csv\")\n",
    "data = data.drop(['Unnamed: 0'], axis=1)\n",
    "data = data.drop(['track_id'], axis=1)\n",
    "data = data.drop(['album_name'], axis=1)\n",
    "data = data.drop(['track_name'], axis=1)\n",
    "\n",
    "# Pruebo escalar los datos numéricos\n",
    "scaler = StandardScaler()\n",
    "numeric_features = ['duration_ms', 'danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "data[numeric_features] = scaler.fit_transform(data[numeric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcion para calcular las estadisticas de las distintas características de las canciones por género"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_estadisticas_por_genero(data, columna, genero):\n",
    "\n",
    "    estadisticas_por_genero = data.groupby(genero)[columna].agg(['max', 'min', 'median', 'mean']).reset_index()\n",
    "\n",
    "    data = pd.merge(data, estadisticas_por_genero.rename(columns={'max': columna + '_max_X_' + genero,\n",
    "                                                                 'min': columna + '_min_X_' + genero,\n",
    "                                                                 'median': columna + '_median_X_' + genero,\n",
    "                                                                 'mean': columna + '_mean_' + genero}),\n",
    "                    on=genero,\n",
    "                    how='left')\n",
    "\n",
    "    return data\n",
    "\n",
    "data = agregar_estadisticas_por_genero(data, 'energy', 'track_genre')\n",
    "data = agregar_estadisticas_por_genero(data, 'danceability', 'track_genre')\n",
    "data = agregar_estadisticas_por_genero(data, 'instrumentalness', 'track_genre')\n",
    "data = agregar_estadisticas_por_genero(data, 'speechiness', 'track_genre')\n",
    "data = agregar_estadisticas_por_genero(data, 'acousticness', 'track_genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculo las estadisticas para la duración de las canciones por artista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['max_duration_by_artist'] = data.groupby('artists')['duration_ms'].transform('max')\n",
    "data['min_duration_by_artist'] = data.groupby('artists')['duration_ms'].transform('min')\n",
    "data['median_duration_by_artist'] = data.groupby('artists')['duration_ms'].transform('median')\n",
    "mean_duration_all_artists = data['duration_ms'].mean()\n",
    "\n",
    "# Imputo datos faltantes con los promedios de cada categoría\n",
    "data['max_duration_by_artist'].fillna(mean_duration_all_artists, inplace=True)\n",
    "data['min_duration_by_artist'].fillna(mean_duration_all_artists, inplace=True)\n",
    "data['median_duration_by_artist'].fillna(mean_duration_all_artists, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "artists                                   True\n",
      "popularity                               False\n",
      "duration_ms                              False\n",
      "explicit                                 False\n",
      "danceability                             False\n",
      "energy                                   False\n",
      "key                                      False\n",
      "loudness                                 False\n",
      "mode                                     False\n",
      "speechiness                              False\n",
      "acousticness                             False\n",
      "instrumentalness                         False\n",
      "liveness                                 False\n",
      "valence                                  False\n",
      "tempo                                    False\n",
      "time_signature                           False\n",
      "track_genre                              False\n",
      "energy_max_X_track_genre                 False\n",
      "energy_min_X_track_genre                 False\n",
      "energy_median_X_track_genre              False\n",
      "energy_mean_track_genre                  False\n",
      "danceability_max_X_track_genre           False\n",
      "danceability_min_X_track_genre           False\n",
      "danceability_median_X_track_genre        False\n",
      "danceability_mean_track_genre            False\n",
      "instrumentalness_max_X_track_genre       False\n",
      "instrumentalness_min_X_track_genre       False\n",
      "instrumentalness_median_X_track_genre    False\n",
      "instrumentalness_mean_track_genre        False\n",
      "speechiness_max_X_track_genre            False\n",
      "speechiness_min_X_track_genre            False\n",
      "speechiness_median_X_track_genre         False\n",
      "speechiness_mean_track_genre             False\n",
      "acousticness_max_X_track_genre           False\n",
      "acousticness_min_X_track_genre           False\n",
      "acousticness_median_X_track_genre        False\n",
      "acousticness_mean_track_genre            False\n",
      "max_duration_by_artist                   False\n",
      "min_duration_by_artist                   False\n",
      "median_duration_by_artist                False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Veo cuales son los NAs pero no hago nada al respecto\n",
    "\n",
    "print(data.isna().any().any()) \n",
    "print(data.isna().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculo la cantidad de explicits por artista y por género"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['explicit'] = data['explicit'].astype(int)\n",
    "data['promedio_explicit_por_artista'] = data.groupby('artists')['explicit'].transform('mean')\n",
    "mean_explicit_all_artists = data['explicit'].mean()\n",
    "data['promedio_explicit_por_artista'].fillna(mean_explicit_all_artists, inplace=True)\n",
    "data['promedio_explicit_por_genero'] = data.groupby('track_genre')['explicit'].transform('mean')\n",
    "mean_explicit_all_artists = data['explicit'].mean()\n",
    "data['promedio_explicit_por_genero'].fillna(mean_explicit_all_artists, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hago label encoding para los artistas y generos (porque tienen que ser únicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etiquetado de artistas\n",
    "artist_encoder = LabelEncoder()\n",
    "data['artist_encoded'] = artist_encoder.fit_transform(data['artists'])\n",
    "data = data.drop(['artists'], axis=1)\n",
    "# Etiquetado de géneros de canciones\n",
    "genre_encoder = LabelEncoder()\n",
    "data['genre_encoded'] = genre_encoder.fit_transform(data['track_genre'])\n",
    "data = data.drop(['track_genre'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defino las variables a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('explicit', axis=1)\n",
    "y = data['explicit']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo Baseline - Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud: 0.9253070175438597\n",
      "Precisión: 0.621160409556314\n",
      "Recall: 0.2849686847599165\n",
      "AUC-ROC: 0.8803395153425284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paula\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Creo el modelo\n",
    "modelo_regresion_logistica = LogisticRegression()\n",
    "\n",
    "modelo_regresion_logistica.fit(X_train, y_train) # Ajusto el modelo a mis datos de entrenamiento (X_train, y_train)\n",
    "\n",
    "predicciones = modelo_regresion_logistica.predict(X_test) # Hago predicciones con el conjunto de prueba (X_test)\n",
    "\n",
    "exactitud = accuracy_score(y_test, predicciones)\n",
    "print(\"Exactitud:\", exactitud)\n",
    "\n",
    "precision = precision_score(y_test, predicciones) # Calculo la precisión\n",
    "print(\"Precisión:\", precision)\n",
    "\n",
    "recall = recall_score(y_test, predicciones) # Calculo el recall\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calcular el área bajo la curva ROC (AUC-ROC)\n",
    "# Probabilidades de predicción para la clase positiva\n",
    "probabilidades_positivas = modelo_regresion_logistica.predict_proba(X_test)[:, 1]\n",
    "auc_roc = roc_auc_score(y_test, probabilidades_positivas)\n",
    "print(\"AUC-ROC:\", auc_roc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 300, 'subsample': 0.8}\n",
      "Exactitud: 0.9742105263157895\n",
      "Precisión: 0.8966547192353644\n",
      "Recall: 0.7834029227557411\n",
      "AUC-ROC: 0.995933397284693\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train) # Defino el objeto DMatrix para los datos de entrenamiento\n",
    "\n",
    "#param_grid = { # Defino los parámetros del modelo XGBoost para clasificación\n",
    "#    'max_depth': [3, 6, 9],\n",
    "#    'min_child_weight': [1, 5, 10],\n",
    "#    'subsample': [0.7, 0.8, 0.9],\n",
    "#    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "#    'learning_rate': [0.01, 0.1, 0.2],\n",
    "#    'n_estimators': [100, 200, 300]\n",
    "#}\n",
    "#xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(y.unique())) # Inicializo el modelo XGBoost\n",
    "#grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1) # Inicializo GridSearchCV\n",
    "#grid_search.fit(X_train, y_train) #Busco los mejores hiperparametros\n",
    "\n",
    "best_params = {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 300, 'subsample': 0.8}\n",
    "print(\"Mejores hiperparámetros:\", best_params)\n",
    "\n",
    "best_xgb_model = xgb.XGBClassifier(**best_params)# Entreno el modelo con los mejores hiperparámetros\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = best_xgb_model.predict(X_test) # Hago predicciones en el conjunto de prueba\n",
    "\n",
    "exactitud = accuracy_score(y_test, predicciones)\n",
    "print(\"Exactitud:\", exactitud)\n",
    "\n",
    "precision = precision_score(y_test, predicciones) # Calculo la precisión\n",
    "print(\"Precisión:\", precision)\n",
    "\n",
    "recall = recall_score(y_test, predicciones) # Calculo el recall\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculo el área bajo la curva ROC (AUC-ROC)\n",
    "probabilidades_positivas = best_xgb_model.predict_proba(X_test)[:, 1]\n",
    "auc_roc = roc_auc_score(y_test, probabilidades_positivas)\n",
    "print(\"AUC-ROC:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 7, 'criterion': 'gini'}\n",
      "Exactitud: 0.9741666666666666\n",
      "Precisión: 0.8961194029850746\n",
      "Recall: 0.7834029227557411\n",
      "AUC-ROC: 0.9898691184708934\n"
     ]
    }
   ],
   "source": [
    "# Defino el modelo de árbol de decisión\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "# Defino los rangos de los hiperparámetros a explorar\n",
    "#param_dist = {\n",
    "#    'max_depth': [3, 5, 7, 9, None],\n",
    "#    'min_samples_split': [2, 5, 10],\n",
    "#    'min_samples_leaf': [1, 2, 4],\n",
    "#    'criterion': ['gini', 'entropy']\n",
    "#}\n",
    "#random_search = RandomizedSearchCV(decision_tree, param_distributions=param_dist, cv=5) # Realizo la búsqueda aleatoria de hiperparámetros con validación cruzada\n",
    "#random_search.fit(X_train, y_train) # Entreno el modelo con la búsqueda aleatoria de hiperparámetros\n",
    "\n",
    "best_params = {'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 7, 'criterion': 'gini'}\n",
    "print(\"Mejores hiperparámetros:\", best_params)\n",
    "\n",
    "# Defino el modelo de árbol de decisión con los mejores hiperparámetros\n",
    "best_decision_tree = DecisionTreeClassifier(**best_params)\n",
    "best_decision_tree.fit(X_train, y_train)\n",
    "predicciones = best_decision_tree.predict(X_test)\n",
    "\n",
    "exactitud = accuracy_score(y_test, predicciones)\n",
    "print(\"Exactitud:\", exactitud)\n",
    "\n",
    "precision = precision_score(y_test, predicciones)\n",
    "print(\"Precisión:\", precision)\n",
    "\n",
    "recall = recall_score(y_test, predicciones)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculo el área bajo la curva ROC (AUC-ROC)\n",
    "probabilidades_positivas = best_decision_tree.predict_proba(X_test)[:, 1]\n",
    "auc_roc = roc_auc_score(y_test, probabilidades_positivas)\n",
    "print(\"AUC-ROC:\", auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud: 0.9741666666666666\n",
      "Precisión: 0.8961194029850746\n",
      "Recall: 0.7834029227557411\n",
      "AUC-ROC: 0.9936978279263246\n"
     ]
    }
   ],
   "source": [
    "# Defino el modelo de Random Forest con hiperparámetros sugeridos\n",
    "random_forest = RandomForestClassifier(n_estimators=2000, max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=42)\n",
    "\n",
    "# Entreno el modelo\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Hago predicciones en el conjunto de prueba\n",
    "predictions = random_forest.predict(X_test)\n",
    "\n",
    "exactitud = accuracy_score(y_test, predicciones)\n",
    "print(\"Exactitud:\", exactitud)\n",
    "\n",
    "precision = precision_score(y_test, predicciones) # Calculo la precisión\n",
    "print(\"Precisión:\", precision)\n",
    "\n",
    "recall = recall_score(y_test, predicciones) # Calculo el recall\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculo el área bajo la curva ROC (AUC-ROC)\n",
    "probabilidades_positivas = random_forest.predict_proba(X_test)[:, 1]\n",
    "auc_roc = roc_auc_score(y_test, probabilidades_positivas)\n",
    "print(\"AUC-ROC:\", auc_roc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
